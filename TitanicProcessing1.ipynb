{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "1.  Data Exploration\n",
    "2.  Simple predictor as a baseline\n",
    "3.  Linear regression\n",
    "4.  Logistical regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                   Moran, Mr. James    male   NaN      0   \n",
      "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "5      0            330877   8.4583   NaN        Q  \n",
      "6      0             17463  51.8625   E46        S  \n",
      "7      1            349909  21.0750   NaN        S  \n",
      "8      2            347742  11.1333   NaN        S  \n",
      "9      0            237736  30.0708   NaN        C  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "#import some packages we expect to use\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as pp\n",
    "from __future__ import division\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "# Read the data.  \n",
    "data = pd.read_csv('input/train.csv')\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations: \n",
    "- We see there are many missing values in many columns.  We'll need to find which columns are missing values and then find a way to fix it so that we are still use the information.\n",
    "- Many columns have non-numeric data.  These will have to be changed to numeric data.  \n",
    "- We can ignore some of the features.  Without domain expertise, we do not know how to leverage some of the data -- we don't know what it means and implies.  We will ignore Cabin and Ticket information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 We expect Age to be important.  We can replace the missing ages with the median age of men and women. \n",
    "medianAgeWomen = data.loc[data['Sex']=='female', 'Age'].median()\n",
    "medianAgeMen = data.loc[data['Sex']=='male', 'Age'].median()\n",
    "data.loc[data['Sex']=='female', 'Age'] = data.loc[data['Sex']=='female', 'Age'].fillna(medianAgeWomen)\n",
    "data.loc[data['Sex']=='male', 'Age'] = data.loc[data['Sex']=='male', 'Age'].fillna(medianAgeMen)\n",
    "\n",
    "#Change Sex and Embarked to numerical values\n",
    "data.loc[data['Sex']=='male', 'Sex'] = 0\n",
    "data.loc[data['Sex']=='female', 'Sex'] = 1\n",
    "\n",
    "#replace missing Embarked value with 'S'\n",
    "data['Embarked'] = data['Embarked'].fillna('S')\n",
    "data.loc[data['Embarked'] == 'S', 'Embarked'] = 0\n",
    "data.loc[data['Embarked'] == 'C', 'Embarked'] = 1\n",
    "data.loc[data['Embarked'] == 'Q', 'Embarked'] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Predictor (Simple, Intuitive, First Pass)\n",
    "\n",
    "Age and Sex seem to be the most intuitive features to correlate survival.  We will do a very quick exploration to see if there is something to our intuition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex  Survived\n",
      "0    0           468\n",
      "     1           109\n",
      "1    1           233\n",
      "     0            81\n",
      "Name: Survived, dtype: int64\n",
      "Survived\n",
      "0    30.193989\n",
      "1    28.232953\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "d= data.groupby('Sex').Survived.value_counts()\n",
    "print d\n",
    "d= data.groupby('Survived').Age.mean()\n",
    "print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean age of the survivors isn't much different than the mean age of all the passengers.  However, women seem to have a much higher survival rate. We can use that as a first cut baseline predictor.  If woman, declare survived.  We can compute the accuracy of such a pedictor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the gender based predictor: 0.786756\n"
     ]
    }
   ],
   "source": [
    "survived = data['Sex']\n",
    "accuracy_gender_based_predictor = sum(data['Survived'] == survived)/len(data['Sex']) \n",
    "print 'Accuracy of the gender based predictor: %f' %accuracy_gender_based_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the test data\n",
    "test_data = pd.read_csv('input/test.csv')\n",
    "test_data.loc[test_data['Sex']=='female', 'Sex'] = 1\n",
    "test_data.loc[test_data['Sex']=='male', 'Sex'] = 0\n",
    "\n",
    "submit_gender_predictor = pd.DataFrame({'PassengerId': test_data['PassengerId'],\n",
    "                                       'Survived':test_data['Sex']})\n",
    "submit_gender_predictor.to_csv('gender_based_predictor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting the results show accuracy of   \n",
    "\n",
    "Let's see if we can do better.  We will try linear regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear  and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize the algorithm class\n",
    "alg = LinearRegression()\n",
    "\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "kf = KFold(data.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (data[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = data[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(data[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the accuracy of the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is really a logistic regression -- we are predicting binary class -- either survived or not survived. \n",
    "Also, python provides functions to do the exercise above much more simply: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79012345679\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation, linear_model\n",
    "\n",
    "# Initialize our algorithm\n",
    "alg = linear_model.LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.\n",
    "kf = cross_validation.KFold(data.shape[0], n_folds=3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(alg, data[predictors], data[\"Survived\"], cv=kf)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy from a logistic regression is about the same as our simple predictor.  We will make submission to check how the predictor performs on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0       3   0  34.5      0      0   7.8292        2\n",
      "1       3   1  47.0      1      0   7.0000        0\n",
      "2       2   0  62.0      0      0   9.6875        2\n",
      "3       3   0  27.0      0      0   8.6625        0\n",
      "4       3   1  22.0      1      1  12.2875        0\n"
     ]
    }
   ],
   "source": [
    "#Process the test data the same way as the training data: \n",
    "\n",
    "test_data.loc[test_data['Sex']==1, 'Age'] = test_data.loc[test_data['Sex']==1, 'Age'].fillna(medianAgeWomen)\n",
    "test_data.loc[test_data['Sex']==0, 'Age'] = test_data.loc[test_data['Sex']==0, 'Age'].fillna(medianAgeMen)\n",
    "\n",
    "#replace missing Embarked value with 'S'\n",
    "test_data['Embarked'] = test_data['Embarked'].fillna('S')\n",
    "test_data.loc[test_data['Embarked'] == 'S', 'Embarked'] = 0\n",
    "test_data.loc[test_data['Embarked'] == 'C', 'Embarked'] = 1\n",
    "test_data.loc[test_data['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "\n",
    "test_data['Fare'] = test_data['Fare'].fillna(0)\n",
    "\n",
    "alg = linear_model.LogisticRegression(random_state=1)\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(data[predictors], data['Survived'])\n",
    "\n",
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(test_data[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submit_logistic_regression_predictor = pd.DataFrame({\n",
    "        'PassengerId': test_data['PassengerId'],\n",
    "        'Survived': predictions\n",
    "    })\n",
    "\n",
    "submit_logistic_regression_predictor.to_csv('submit_logistic_regression_predictor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting the results show accuracy of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will try a Random Forest classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786756453423\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "#use default parameters for Random Forest classifier.\n",
    "alg = RandomForestClassifier(random_state = 1)\n",
    "kf = cross_validation.KFold(data.shape[0], n_folds = 3, random_state = 1)\n",
    "scores = cross_validation.cross_val_score(alg, data[predictors], data['Survived'], cv=kf)\n",
    "print (scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do some feature engineering next to improve the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate Family size\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch']+1 #include self in the family. \n",
    "\n",
    "import re\n",
    "#generate titles \n",
    "def extractTitle(name):\n",
    "    if(name is not None):\n",
    "        title = re.search(r'([A-Z][a-z]+)\\.', name)\n",
    "        if title:\n",
    "            return title.group(1)\n",
    "        return \"\"\n",
    "    return \"\"\n",
    "data['Title'] = data['Name'].apply(extractTitle)\n",
    "data['Title'].value_counts()\n",
    "title_code = {'Mr':1, 'Don': 1, 'Miss':2, 'Ms':2, 'Mlle':2, 'Mrs':3, 'Mme': 3, 'Master':4, 'Dr':5, 'Rev':6, \n",
    "              'Col':7, 'Major':7, 'Capt':7, 'Countess':8, 'Lady':8, 'Jonkheer':8, 'Sir':9}\n",
    "data['Title_code'] = [title_code[x] for x in data['Title']]\n",
    "\n",
    "# Collect the people in a family.  Use lastname + family size to identify. Then assign a numerical value to the family. \n",
    "data['Family'] =  [x.split(\",\")[0] for x in data['Name']]\n",
    "data.loc[data['FamilySize'] == 1, 'Family'] = 'noFamily'\n",
    "data['Family'] = data['Family'] + [str(x) for x in data['FamilySize']]\n",
    "FamilyDic = dict(zip(data['Family'].unique(), range(len(data['Family'].unique()))))\n",
    "data['Family'] = [FamilyDic[x] for x in data['Family']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's see whether any of the features that we have generated are useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0xe294198>,\n",
       "  <matplotlib.axis.XTick at 0xdda5eb8>,\n",
       "  <matplotlib.axis.XTick at 0xe361ba8>,\n",
       "  <matplotlib.axis.XTick at 0xe5f41d0>,\n",
       "  <matplotlib.axis.XTick at 0xe5f4828>,\n",
       "  <matplotlib.axis.XTick at 0xe5f4e80>,\n",
       "  <matplotlib.axis.XTick at 0xe5fe518>,\n",
       "  <matplotlib.axis.XTick at 0xe5feb70>,\n",
       "  <matplotlib.axis.XTick at 0xe60a208>,\n",
       "  <matplotlib.axis.XTick at 0xe60a860>],\n",
       " <a list of 10 Text xticklabel objects>)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEsCAYAAAAIBeLrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyP8HYGdTKKe1MOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xddb7e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "#we have added new features: \n",
    "predictor = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"Family\", \"FamilySize\", \"Title_code\"]\n",
    "s = SelectKBest(f_classif, k = 5)\n",
    "s.fit(data[predictor], data['Survived'])\n",
    "\n",
    "scores = -np.log10(s.pvalues_)\n",
    "\n",
    "pyplot.bar(range(len(predictor)), scores)\n",
    "pyplot.xticks(range(len(predictor)), predictor, rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the five highest values to generate a solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826038159371\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf= 4)\n",
    "score = cross_validation.cross_val_score(alg, data[predictor], data['Survived'], cv = kf)\n",
    "print(mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the same features for the test set and then prepare a submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch']+1 #include self in the family. \n",
    "\n",
    "#generate titles \n",
    "\n",
    "test_data['Title'] = test_data['Name'].apply(extractTitle)\n",
    "\n",
    "#use the same titlecode as before. \n",
    "test_data['Title_code'] = [title_code.get(x, -1) for x in test_data['Title']]\n",
    "\n",
    "# Collect the people in a family.  Use lastname + family size to identify. Then assign a numerical value to the family. \n",
    "test_data['Family'] =  [x.split(\",\")[0] for x in test_data['Name']]\n",
    "test_data.loc[test_data['FamilySize'] == 1, 'Family'] = 'noFamily'\n",
    "test_data['Family'] = test_data['Family'] + [str(x) for x in test_data['FamilySize']]\n",
    "test_data['Family'] = [FamilyDic.get(x, -1) for x in test_data['Family']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg.fit(data[predictor], data['Survived'])\n",
    "prediction = alg.predict(test_data[predictor])\n",
    "submission = pd.DataFrame({'PassengerId': test_data['PassengerId'], \n",
    "                          'Survived' : prediction})\n",
    "submission.to_csv('submit_random_forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy with this submission is: \n",
    "\n",
    "There are many more things to try with this dataset and I  hope to return to try them soon. \n",
    "1. What if we tried gradient boosting? \n",
    "2. What if we averaged the results from multiple classifiers, as in an ensemble? \n",
    "3. What if we used a vote from each classifier? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
